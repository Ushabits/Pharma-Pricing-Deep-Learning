{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57d677ca-9f00-4f40-a631-c4c6cd6e4feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: indian_pharmaceutical_products_clean.csv\n",
      "Rows: 253973\n",
      "Columns: ['product_id', 'brand_name', 'manufacturer', 'price_inr', 'is_discontinued', 'dosage_form', 'pack_size', 'pack_unit', 'num_active_ingredients', 'primary_ingredient', 'primary_strength', 'active_ingredients', 'therapeutic_class', 'packaging_raw', 'manufacturer_raw']\n",
      "Using columns: ['product_id', 'brand_name', 'manufacturer', 'price_inr', 'dosage_form', 'pack_size', 'pack_unit', 'num_active_ingredients', 'primary_ingredient', 'primary_strength', 'active_ingredients', 'therapeutic_class']\n",
      "SBERT not available or failed — falling back to Keras TextVectorization + BiLSTM encoder.\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 46ms/step\n",
      "sizes: 190479 31747 31747\n",
      "Class weights: {0: 0.9921401337583599, 1: 0.9935840257890866, 2: 1.014589325663151}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_17\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_17\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ manu_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                    │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dosage_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                    │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ manu_emb (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">121,760</span> │ manu_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dos_emb (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span> │ dosage_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ emb_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ manu_emb[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dos_emb[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ num_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ emb_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ flatten_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ flatten_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ num_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">31,488</span> │ concatenate_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ tier (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ manu_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m)                    │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dosage_input (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m)                    │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ manu_emb (\u001b[38;5;33mEmbedding\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │         \u001b[38;5;34m121,760\u001b[0m │ manu_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dos_emb (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                 │              \u001b[38;5;34m68\u001b[0m │ dosage_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ emb_input (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_8 (\u001b[38;5;33mFlatten\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ manu_emb[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_9 (\u001b[38;5;33mFlatten\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ dos_emb[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ num_input (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_9 (\u001b[38;5;33mConcatenate\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m122\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ emb_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ flatten_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ flatten_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ num_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │          \u001b[38;5;34m31,488\u001b[0m │ concatenate_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │           \u001b[38;5;34m1,024\u001b[0m │ dense_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_42 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m32,896\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │             \u001b[38;5;34m512\u001b[0m │ dense_42[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_43 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ tier (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                 │             \u001b[38;5;34m195\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">196,199</span> (766.40 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m196,199\u001b[0m (766.40 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">195,431</span> (763.40 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m195,431\u001b[0m (763.40 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      " — val_macro_f1: 0.5889\n",
      "\n",
      "Epoch 1: val_macro_f1 improved from None to 0.58886, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 9s - 12ms/step - accuracy: 0.4645 - loss: 1.1426 - val_accuracy: 0.5886 - val_loss: 0.8838 - val_macro_f1: 0.5889 - learning_rate: 1.0000e-04\n",
      "Epoch 2/60\n",
      " — val_macro_f1: 0.6224\n",
      "\n",
      "Epoch 2: val_macro_f1 improved from 0.58886 to 0.62241, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 7s - 9ms/step - accuracy: 0.5280 - loss: 0.9816 - val_accuracy: 0.6228 - val_loss: 0.8391 - val_macro_f1: 0.6224 - learning_rate: 1.0000e-04\n",
      "Epoch 3/60\n",
      " — val_macro_f1: 0.6451\n",
      "\n",
      "Epoch 3: val_macro_f1 improved from 0.62241 to 0.64506, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 6s - 8ms/step - accuracy: 0.5659 - loss: 0.9197 - val_accuracy: 0.6466 - val_loss: 0.8033 - val_macro_f1: 0.6451 - learning_rate: 1.0000e-04\n",
      "Epoch 4/60\n",
      " — val_macro_f1: 0.6642\n",
      "\n",
      "Epoch 4: val_macro_f1 improved from 0.64506 to 0.66421, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 5s - 7ms/step - accuracy: 0.5980 - loss: 0.8707 - val_accuracy: 0.6660 - val_loss: 0.7703 - val_macro_f1: 0.6642 - learning_rate: 1.0000e-04\n",
      "Epoch 5/60\n",
      " — val_macro_f1: 0.6753\n",
      "\n",
      "Epoch 5: val_macro_f1 improved from 0.66421 to 0.67535, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 5s - 7ms/step - accuracy: 0.6208 - loss: 0.8335 - val_accuracy: 0.6777 - val_loss: 0.7472 - val_macro_f1: 0.6753 - learning_rate: 1.0000e-04\n",
      "Epoch 6/60\n",
      " — val_macro_f1: 0.6848\n",
      "\n",
      "Epoch 6: val_macro_f1 improved from 0.67535 to 0.68481, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 5s - 7ms/step - accuracy: 0.6394 - loss: 0.8028 - val_accuracy: 0.6869 - val_loss: 0.7278 - val_macro_f1: 0.6848 - learning_rate: 1.0000e-04\n",
      "Epoch 7/60\n",
      " — val_macro_f1: 0.6917\n",
      "\n",
      "Epoch 7: val_macro_f1 improved from 0.68481 to 0.69175, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 5s - 7ms/step - accuracy: 0.6522 - loss: 0.7782 - val_accuracy: 0.6933 - val_loss: 0.7117 - val_macro_f1: 0.6917 - learning_rate: 1.0000e-04\n",
      "Epoch 8/60\n",
      " — val_macro_f1: 0.6993\n",
      "\n",
      "Epoch 8: val_macro_f1 improved from 0.69175 to 0.69929, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 5s - 7ms/step - accuracy: 0.6623 - loss: 0.7565 - val_accuracy: 0.7008 - val_loss: 0.6938 - val_macro_f1: 0.6993 - learning_rate: 1.0000e-04\n",
      "Epoch 9/60\n",
      " — val_macro_f1: 0.7135\n",
      "\n",
      "Epoch 9: val_macro_f1 improved from 0.69929 to 0.71346, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 6s - 8ms/step - accuracy: 0.6763 - loss: 0.7306 - val_accuracy: 0.7149 - val_loss: 0.6636 - val_macro_f1: 0.7135 - learning_rate: 1.0000e-04\n",
      "Epoch 10/60\n",
      " — val_macro_f1: 0.7391\n",
      "\n",
      "Epoch 10: val_macro_f1 improved from 0.71346 to 0.73914, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 6s - 7ms/step - accuracy: 0.6961 - loss: 0.6878 - val_accuracy: 0.7403 - val_loss: 0.6046 - val_macro_f1: 0.7391 - learning_rate: 1.0000e-04\n",
      "Epoch 11/60\n",
      " — val_macro_f1: 0.7862\n",
      "\n",
      "Epoch 11: val_macro_f1 improved from 0.73914 to 0.78618, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 5s - 7ms/step - accuracy: 0.7286 - loss: 0.6199 - val_accuracy: 0.7869 - val_loss: 0.5060 - val_macro_f1: 0.7862 - learning_rate: 1.0000e-04\n",
      "Epoch 12/60\n",
      " — val_macro_f1: 0.8227\n",
      "\n",
      "Epoch 12: val_macro_f1 improved from 0.78618 to 0.82275, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 5s - 7ms/step - accuracy: 0.7615 - loss: 0.5455 - val_accuracy: 0.8236 - val_loss: 0.4225 - val_macro_f1: 0.8227 - learning_rate: 1.0000e-04\n",
      "Epoch 13/60\n",
      " — val_macro_f1: 0.8487\n",
      "\n",
      "Epoch 13: val_macro_f1 improved from 0.82275 to 0.84869, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 5s - 7ms/step - accuracy: 0.7883 - loss: 0.4886 - val_accuracy: 0.8494 - val_loss: 0.3658 - val_macro_f1: 0.8487 - learning_rate: 1.0000e-04\n",
      "Epoch 14/60\n",
      " — val_macro_f1: 0.8653\n",
      "\n",
      "Epoch 14: val_macro_f1 improved from 0.84869 to 0.86533, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 5s - 7ms/step - accuracy: 0.8068 - loss: 0.4498 - val_accuracy: 0.8659 - val_loss: 0.3286 - val_macro_f1: 0.8653 - learning_rate: 1.0000e-04\n",
      "Epoch 15/60\n",
      " — val_macro_f1: 0.8732\n",
      "\n",
      "Epoch 15: val_macro_f1 improved from 0.86533 to 0.87321, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 5s - 7ms/step - accuracy: 0.8194 - loss: 0.4249 - val_accuracy: 0.8740 - val_loss: 0.3090 - val_macro_f1: 0.8732 - learning_rate: 1.0000e-04\n",
      "Epoch 16/60\n",
      " — val_macro_f1: 0.8795\n",
      "\n",
      "Epoch 16: val_macro_f1 improved from 0.87321 to 0.87952, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 6s - 8ms/step - accuracy: 0.8249 - loss: 0.4097 - val_accuracy: 0.8801 - val_loss: 0.2940 - val_macro_f1: 0.8795 - learning_rate: 1.0000e-04\n",
      "Epoch 17/60\n",
      " — val_macro_f1: 0.8856\n",
      "\n",
      "Epoch 17: val_macro_f1 improved from 0.87952 to 0.88555, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 5s - 7ms/step - accuracy: 0.8332 - loss: 0.3949 - val_accuracy: 0.8860 - val_loss: 0.2819 - val_macro_f1: 0.8856 - learning_rate: 1.0000e-04\n",
      "Epoch 18/60\n",
      " — val_macro_f1: 0.8905\n",
      "\n",
      "Epoch 18: val_macro_f1 improved from 0.88555 to 0.89050, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 5s - 7ms/step - accuracy: 0.8382 - loss: 0.3805 - val_accuracy: 0.8908 - val_loss: 0.2717 - val_macro_f1: 0.8905 - learning_rate: 1.0000e-04\n",
      "Epoch 19/60\n",
      " — val_macro_f1: 0.8947\n",
      "\n",
      "Epoch 19: val_macro_f1 improved from 0.89050 to 0.89468, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 5s - 7ms/step - accuracy: 0.8440 - loss: 0.3693 - val_accuracy: 0.8949 - val_loss: 0.2609 - val_macro_f1: 0.8947 - learning_rate: 1.0000e-04\n",
      "Epoch 20/60\n",
      " — val_macro_f1: 0.8990\n",
      "\n",
      "Epoch 20: val_macro_f1 improved from 0.89468 to 0.89900, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 5s - 7ms/step - accuracy: 0.8483 - loss: 0.3579 - val_accuracy: 0.8990 - val_loss: 0.2540 - val_macro_f1: 0.8990 - learning_rate: 1.0000e-04\n",
      "Epoch 21/60\n",
      " — val_macro_f1: 0.9023\n",
      "\n",
      "Epoch 21: val_macro_f1 improved from 0.89900 to 0.90228, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 5s - 7ms/step - accuracy: 0.8528 - loss: 0.3483 - val_accuracy: 0.9023 - val_loss: 0.2452 - val_macro_f1: 0.9023 - learning_rate: 1.0000e-04\n",
      "Epoch 22/60\n",
      " — val_macro_f1: 0.9012\n",
      "\n",
      "Epoch 22: val_macro_f1 did not improve from 0.90228\n",
      "745/745 - 5s - 7ms/step - accuracy: 0.8579 - loss: 0.3379 - val_accuracy: 0.9012 - val_loss: 0.2423 - val_macro_f1: 0.9012 - learning_rate: 1.0000e-04\n",
      "Epoch 23/60\n",
      " — val_macro_f1: 0.9050\n",
      "\n",
      "Epoch 23: val_macro_f1 improved from 0.90228 to 0.90496, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 5s - 7ms/step - accuracy: 0.8608 - loss: 0.3313 - val_accuracy: 0.9049 - val_loss: 0.2369 - val_macro_f1: 0.9050 - learning_rate: 1.0000e-04\n",
      "Epoch 24/60\n",
      " — val_macro_f1: 0.9066\n",
      "\n",
      "Epoch 24: val_macro_f1 improved from 0.90496 to 0.90662, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 5s - 7ms/step - accuracy: 0.8635 - loss: 0.3243 - val_accuracy: 0.9065 - val_loss: 0.2315 - val_macro_f1: 0.9066 - learning_rate: 1.0000e-04\n",
      "Epoch 25/60\n",
      " — val_macro_f1: 0.9110\n",
      "\n",
      "Epoch 25: val_macro_f1 improved from 0.90662 to 0.91104, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 5s - 7ms/step - accuracy: 0.8672 - loss: 0.3163 - val_accuracy: 0.9110 - val_loss: 0.2226 - val_macro_f1: 0.9110 - learning_rate: 1.0000e-04\n",
      "Epoch 26/60\n",
      " — val_macro_f1: 0.9111\n",
      "\n",
      "Epoch 26: val_macro_f1 improved from 0.91104 to 0.91108, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 5s - 7ms/step - accuracy: 0.8698 - loss: 0.3119 - val_accuracy: 0.9110 - val_loss: 0.2195 - val_macro_f1: 0.9111 - learning_rate: 1.0000e-04\n",
      "Epoch 27/60\n",
      " — val_macro_f1: 0.9139\n",
      "\n",
      "Epoch 27: val_macro_f1 improved from 0.91108 to 0.91390, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 5s - 7ms/step - accuracy: 0.8734 - loss: 0.3022 - val_accuracy: 0.9136 - val_loss: 0.2159 - val_macro_f1: 0.9139 - learning_rate: 1.0000e-04\n",
      "Epoch 28/60\n",
      " — val_macro_f1: 0.9135\n",
      "\n",
      "Epoch 28: val_macro_f1 did not improve from 0.91390\n",
      "745/745 - 6s - 9ms/step - accuracy: 0.8771 - loss: 0.2940 - val_accuracy: 0.9131 - val_loss: 0.2128 - val_macro_f1: 0.9135 - learning_rate: 1.0000e-04\n",
      "Epoch 29/60\n",
      " — val_macro_f1: 0.9215\n",
      "\n",
      "Epoch 29: val_macro_f1 improved from 0.91390 to 0.92153, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 6s - 8ms/step - accuracy: 0.8823 - loss: 0.2847 - val_accuracy: 0.9213 - val_loss: 0.1956 - val_macro_f1: 0.9215 - learning_rate: 1.0000e-04\n",
      "Epoch 30/60\n",
      " — val_macro_f1: 0.9208\n",
      "\n",
      "Epoch 30: val_macro_f1 did not improve from 0.92153\n",
      "745/745 - 5s - 7ms/step - accuracy: 0.8849 - loss: 0.2761 - val_accuracy: 0.9204 - val_loss: 0.1943 - val_macro_f1: 0.9208 - learning_rate: 1.0000e-04\n",
      "Epoch 31/60\n",
      " — val_macro_f1: 0.9242\n",
      "\n",
      "Epoch 31: val_macro_f1 improved from 0.92153 to 0.92415, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 5s - 7ms/step - accuracy: 0.8894 - loss: 0.2668 - val_accuracy: 0.9237 - val_loss: 0.1884 - val_macro_f1: 0.9242 - learning_rate: 1.0000e-04\n",
      "Epoch 32/60\n",
      " — val_macro_f1: 0.9262\n",
      "\n",
      "Epoch 32: val_macro_f1 improved from 0.92415 to 0.92623, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 6s - 7ms/step - accuracy: 0.8919 - loss: 0.2606 - val_accuracy: 0.9259 - val_loss: 0.1815 - val_macro_f1: 0.9262 - learning_rate: 1.0000e-04\n",
      "Epoch 33/60\n",
      " — val_macro_f1: 0.9257\n",
      "\n",
      "Epoch 33: val_macro_f1 did not improve from 0.92623\n",
      "745/745 - 5s - 7ms/step - accuracy: 0.8948 - loss: 0.2529 - val_accuracy: 0.9253 - val_loss: 0.1805 - val_macro_f1: 0.9257 - learning_rate: 1.0000e-04\n",
      "Epoch 34/60\n",
      " — val_macro_f1: 0.9251\n",
      "\n",
      "Epoch 34: val_macro_f1 did not improve from 0.92623\n",
      "745/745 - 5s - 7ms/step - accuracy: 0.8988 - loss: 0.2437 - val_accuracy: 0.9247 - val_loss: 0.1801 - val_macro_f1: 0.9251 - learning_rate: 1.0000e-04\n",
      "Epoch 35/60\n",
      " — val_macro_f1: 0.9308\n",
      "\n",
      "Epoch 35: val_macro_f1 improved from 0.92623 to 0.93079, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 7s - 10ms/step - accuracy: 0.9019 - loss: 0.2365 - val_accuracy: 0.9305 - val_loss: 0.1688 - val_macro_f1: 0.9308 - learning_rate: 1.0000e-04\n",
      "Epoch 36/60\n",
      " — val_macro_f1: 0.9318\n",
      "\n",
      "Epoch 36: val_macro_f1 improved from 0.93079 to 0.93180, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 8s - 10ms/step - accuracy: 0.9052 - loss: 0.2280 - val_accuracy: 0.9314 - val_loss: 0.1664 - val_macro_f1: 0.9318 - learning_rate: 1.0000e-04\n",
      "Epoch 37/60\n",
      " — val_macro_f1: 0.9326\n",
      "\n",
      "Epoch 37: val_macro_f1 improved from 0.93180 to 0.93264, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 7s - 10ms/step - accuracy: 0.9084 - loss: 0.2205 - val_accuracy: 0.9322 - val_loss: 0.1642 - val_macro_f1: 0.9326 - learning_rate: 1.0000e-04\n",
      "Epoch 38/60\n",
      " — val_macro_f1: 0.9350\n",
      "\n",
      "Epoch 38: val_macro_f1 improved from 0.93264 to 0.93498, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 8s - 11ms/step - accuracy: 0.9103 - loss: 0.2158 - val_accuracy: 0.9346 - val_loss: 0.1572 - val_macro_f1: 0.9350 - learning_rate: 1.0000e-04\n",
      "Epoch 39/60\n",
      " — val_macro_f1: 0.9328\n",
      "\n",
      "Epoch 39: val_macro_f1 did not improve from 0.93498\n",
      "745/745 - 8s - 11ms/step - accuracy: 0.9137 - loss: 0.2102 - val_accuracy: 0.9323 - val_loss: 0.1611 - val_macro_f1: 0.9328 - learning_rate: 1.0000e-04\n",
      "Epoch 40/60\n",
      " — val_macro_f1: 0.9382\n",
      "\n",
      "Epoch 40: val_macro_f1 improved from 0.93498 to 0.93818, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 7s - 9ms/step - accuracy: 0.9154 - loss: 0.2043 - val_accuracy: 0.9378 - val_loss: 0.1503 - val_macro_f1: 0.9382 - learning_rate: 1.0000e-04\n",
      "Epoch 41/60\n",
      " — val_macro_f1: 0.9368\n",
      "\n",
      "Epoch 41: val_macro_f1 did not improve from 0.93818\n",
      "745/745 - 5s - 7ms/step - accuracy: 0.9173 - loss: 0.2014 - val_accuracy: 0.9365 - val_loss: 0.1526 - val_macro_f1: 0.9368 - learning_rate: 1.0000e-04\n",
      "Epoch 42/60\n",
      " — val_macro_f1: 0.9372\n",
      "\n",
      "Epoch 42: val_macro_f1 did not improve from 0.93818\n",
      "745/745 - 5s - 7ms/step - accuracy: 0.9205 - loss: 0.1942 - val_accuracy: 0.9368 - val_loss: 0.1516 - val_macro_f1: 0.9372 - learning_rate: 1.0000e-04\n",
      "Epoch 43/60\n",
      " — val_macro_f1: 0.9394\n",
      "\n",
      "Epoch 43: val_macro_f1 improved from 0.93818 to 0.93943, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 5s - 7ms/step - accuracy: 0.9214 - loss: 0.1901 - val_accuracy: 0.9391 - val_loss: 0.1476 - val_macro_f1: 0.9394 - learning_rate: 1.0000e-04\n",
      "Epoch 44/60\n",
      " — val_macro_f1: 0.9390\n",
      "\n",
      "Epoch 44: val_macro_f1 did not improve from 0.93943\n",
      "745/745 - 5s - 6ms/step - accuracy: 0.9238 - loss: 0.1862 - val_accuracy: 0.9388 - val_loss: 0.1466 - val_macro_f1: 0.9390 - learning_rate: 1.0000e-04\n",
      "Epoch 45/60\n",
      " — val_macro_f1: 0.9374\n",
      "\n",
      "Epoch 45: val_macro_f1 did not improve from 0.93943\n",
      "745/745 - 5s - 7ms/step - accuracy: 0.9243 - loss: 0.1837 - val_accuracy: 0.9371 - val_loss: 0.1501 - val_macro_f1: 0.9374 - learning_rate: 1.0000e-04\n",
      "Epoch 46/60\n",
      " — val_macro_f1: 0.9371\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 46: val_macro_f1 did not improve from 0.93943\n",
      "745/745 - 5s - 6ms/step - accuracy: 0.9265 - loss: 0.1798 - val_accuracy: 0.9368 - val_loss: 0.1503 - val_macro_f1: 0.9371 - learning_rate: 1.0000e-04\n",
      "Epoch 47/60\n",
      " — val_macro_f1: 0.9404\n",
      "\n",
      "Epoch 47: val_macro_f1 improved from 0.93943 to 0.94042, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 5s - 7ms/step - accuracy: 0.9311 - loss: 0.1693 - val_accuracy: 0.9401 - val_loss: 0.1462 - val_macro_f1: 0.9404 - learning_rate: 5.0000e-05\n",
      "Epoch 48/60\n",
      " — val_macro_f1: 0.9417\n",
      "\n",
      "Epoch 48: val_macro_f1 improved from 0.94042 to 0.94172, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 5s - 7ms/step - accuracy: 0.9317 - loss: 0.1669 - val_accuracy: 0.9414 - val_loss: 0.1444 - val_macro_f1: 0.9417 - learning_rate: 5.0000e-05\n",
      "Epoch 49/60\n",
      " — val_macro_f1: 0.9419\n",
      "\n",
      "Epoch 49: val_macro_f1 improved from 0.94172 to 0.94188, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 5s - 7ms/step - accuracy: 0.9326 - loss: 0.1648 - val_accuracy: 0.9416 - val_loss: 0.1431 - val_macro_f1: 0.9419 - learning_rate: 5.0000e-05\n",
      "Epoch 50/60\n",
      " — val_macro_f1: 0.9411\n",
      "\n",
      "Epoch 50: val_macro_f1 did not improve from 0.94188\n",
      "745/745 - 5s - 6ms/step - accuracy: 0.9337 - loss: 0.1632 - val_accuracy: 0.9408 - val_loss: 0.1458 - val_macro_f1: 0.9411 - learning_rate: 5.0000e-05\n",
      "Epoch 51/60\n",
      " — val_macro_f1: 0.9412\n",
      "\n",
      "Epoch 51: val_macro_f1 did not improve from 0.94188\n",
      "745/745 - 5s - 7ms/step - accuracy: 0.9339 - loss: 0.1619 - val_accuracy: 0.9409 - val_loss: 0.1445 - val_macro_f1: 0.9412 - learning_rate: 5.0000e-05\n",
      "Epoch 52/60\n",
      " — val_macro_f1: 0.9426\n",
      "\n",
      "Epoch 52: val_macro_f1 improved from 0.94188 to 0.94261, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 6s - 8ms/step - accuracy: 0.9348 - loss: 0.1594 - val_accuracy: 0.9423 - val_loss: 0.1418 - val_macro_f1: 0.9426 - learning_rate: 5.0000e-05\n",
      "Epoch 53/60\n",
      " — val_macro_f1: 0.9414\n",
      "\n",
      "Epoch 53: val_macro_f1 did not improve from 0.94261\n",
      "745/745 - 5s - 7ms/step - accuracy: 0.9350 - loss: 0.1586 - val_accuracy: 0.9411 - val_loss: 0.1425 - val_macro_f1: 0.9414 - learning_rate: 5.0000e-05\n",
      "Epoch 54/60\n",
      " — val_macro_f1: 0.9420\n",
      "\n",
      "Epoch 54: val_macro_f1 did not improve from 0.94261\n",
      "745/745 - 7s - 9ms/step - accuracy: 0.9360 - loss: 0.1568 - val_accuracy: 0.9417 - val_loss: 0.1447 - val_macro_f1: 0.9420 - learning_rate: 5.0000e-05\n",
      "Epoch 55/60\n",
      " — val_macro_f1: 0.9425\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 55: val_macro_f1 did not improve from 0.94261\n",
      "745/745 - 6s - 8ms/step - accuracy: 0.9360 - loss: 0.1558 - val_accuracy: 0.9422 - val_loss: 0.1413 - val_macro_f1: 0.9425 - learning_rate: 5.0000e-05\n",
      "Epoch 56/60\n",
      " — val_macro_f1: 0.9439\n",
      "\n",
      "Epoch 56: val_macro_f1 improved from 0.94261 to 0.94389, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 6s - 8ms/step - accuracy: 0.9395 - loss: 0.1495 - val_accuracy: 0.9436 - val_loss: 0.1387 - val_macro_f1: 0.9439 - learning_rate: 2.5000e-05\n",
      "Epoch 57/60\n",
      " — val_macro_f1: 0.9436\n",
      "\n",
      "Epoch 57: val_macro_f1 did not improve from 0.94389\n",
      "745/745 - 5s - 7ms/step - accuracy: 0.9390 - loss: 0.1488 - val_accuracy: 0.9433 - val_loss: 0.1378 - val_macro_f1: 0.9436 - learning_rate: 2.5000e-05\n",
      "Epoch 58/60\n",
      " — val_macro_f1: 0.9430\n",
      "\n",
      "Epoch 58: val_macro_f1 did not improve from 0.94389\n",
      "745/745 - 5s - 7ms/step - accuracy: 0.9397 - loss: 0.1480 - val_accuracy: 0.9426 - val_loss: 0.1429 - val_macro_f1: 0.9430 - learning_rate: 2.5000e-05\n",
      "Epoch 59/60\n",
      " — val_macro_f1: 0.9438\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 59: val_macro_f1 did not improve from 0.94389\n",
      "745/745 - 5s - 7ms/step - accuracy: 0.9407 - loss: 0.1471 - val_accuracy: 0.9435 - val_loss: 0.1391 - val_macro_f1: 0.9438 - learning_rate: 2.5000e-05\n",
      "Epoch 60/60\n",
      " — val_macro_f1: 0.9452\n",
      "\n",
      "Epoch 60: val_macro_f1 improved from 0.94389 to 0.94521, saving model to tier_nn_improved.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 - 5s - 7ms/step - accuracy: 0.9406 - loss: 0.1456 - val_accuracy: 0.9449 - val_loss: 0.1360 - val_macro_f1: 0.9452 - learning_rate: 1.2500e-05\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 0.9463886351466281\n",
      "Test macro F1: 0.9467127559302352\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9615    0.9316    0.9463     10666\n",
      "           1     0.9069    0.9374    0.9219     10651\n",
      "           2     0.9732    0.9708    0.9720     10430\n",
      "\n",
      "    accuracy                         0.9464     31747\n",
      "   macro avg     0.9472    0.9466    0.9467     31747\n",
      "weighted avg     0.9470    0.9464    0.9465     31747\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 9936   725     5]\n",
      " [  393  9984   274]\n",
      " [    5   300 10125]]\n",
      "Saved model -> tier_nn_improved.h5\n"
     ]
    }
   ],
   "source": [
    "# Improved Tier Classification — full cell to paste into your notebook\n",
    "# Replace DATA_PATH if the provided path isn't your dataset CSV.\n",
    "DATA_PATH = \"indian_pharmaceutical_products_clean.csv\"  # update if needed\n",
    "\n",
    "import os, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, losses, callbacks\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "RND = 42\n",
    "np.random.seed(RND)\n",
    "tf.random.set_seed(RND)\n",
    "\n",
    "# -----------------------\n",
    "# 0. Load data\n",
    "# -----------------------\n",
    "print(\"Loading:\", DATA_PATH)\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "# Keep only relevant columns (you listed these earlier); adjust if names differ\n",
    "cols_keep = ['product_id','brand_name','manufacturer','price_inr','dosage_form','pack_size','pack_unit',\n",
    "             'num_active_ingredients','primary_ingredient','primary_strength','active_ingredients','therapeutic_class']\n",
    "use_cols = [c for c in cols_keep if c in df.columns]\n",
    "df = df[use_cols].copy()\n",
    "print(\"Using columns:\", use_cols)\n",
    "\n",
    "# -----------------------\n",
    "# 1. Lightweight cleaning & parsing\n",
    "# -----------------------\n",
    "def normalize_text(s):\n",
    "    s = str(s).lower()\n",
    "    s = re.sub(r'[\\(\\)\\[\\]\\{\\},;:/\\\\\\|\"]', ' ', s)\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    s = re.sub(r'(\\d+)\\s*mg', r'\\1mg', s)\n",
    "    s = re.sub(r'(\\d+)\\s*ml', r'\\1ml', s)\n",
    "    return s\n",
    "\n",
    "def parse_strength(s):\n",
    "    s = str(s).lower()\n",
    "    m = re.search(r'(\\d+(?:\\.\\d+)?)\\s*(mcg|mg|g|µg|iu)?', s)\n",
    "    if not m: return np.nan\n",
    "    v = float(m.group(1)); unit = (m.group(2) or '').replace('µg','mcg')\n",
    "    if unit == 'mcg': return v/1000.0\n",
    "    if unit == 'g': return v*1000.0\n",
    "    return v\n",
    "\n",
    "def parse_pack(size, unit):\n",
    "    try:\n",
    "        if not pd.isna(size): return int(size)\n",
    "    except: pass\n",
    "    m = re.search(r'(\\d+)', str(unit).lower())\n",
    "    return int(m.group(1)) if m else np.nan\n",
    "\n",
    "# Fill/convert safely\n",
    "df['brand_name'] = df.get('brand_name','').fillna('').astype(str)\n",
    "df['manufacturer'] = df.get('manufacturer','').fillna('unknown').astype(str)\n",
    "df['primary_ingredient'] = df.get('primary_ingredient','').fillna('').astype(str)\n",
    "df['active_ingredients'] = df.get('active_ingredients','').fillna('').astype(str)\n",
    "df['primary_strength'] = df.get('primary_strength','').fillna('').astype(str)\n",
    "df['dosage_form'] = df.get('dosage_form','').fillna('').astype(str)\n",
    "df['pack_size'] = pd.to_numeric(df.get('pack_size', pd.NA), errors='coerce')\n",
    "\n",
    "# parsed fields\n",
    "df['brand_clean'] = df['brand_name'].apply(normalize_text)\n",
    "df['primary_ing_clean'] = df['primary_ingredient'].apply(normalize_text)\n",
    "df['active_ing_clean'] = df['active_ingredients'].apply(normalize_text)\n",
    "df['strength_mg'] = df['primary_strength'].apply(parse_strength)\n",
    "df['pack_num'] = df.apply(lambda r: parse_pack(r.get('pack_size', pd.NA), r.get('pack_unit','')), axis=1)\n",
    "\n",
    "# safe fills\n",
    "df['pack_num'] = df['pack_num'].fillna(df['pack_num'].median())\n",
    "df['strength_mg'] = df['strength_mg'].fillna(df['strength_mg'].median())\n",
    "\n",
    "# combined text\n",
    "df['composition_text'] = (df['primary_ing_clean'] + ' ' + df['active_ing_clean']).str.strip()\n",
    "df['text_for_emb'] = (df['brand_clean'] + ' || ' + df['composition_text'] + ' || ' + df['dosage_form'].str.lower()).str.strip()\n",
    "\n",
    "# -----------------------\n",
    "# 2. Build price_tier (target) if not present\n",
    "# -----------------------\n",
    "if 'price_inr' not in df.columns:\n",
    "    raise SystemExit(\"price_inr required for generating tiers. Provide a dataset with price_inr.\")\n",
    "df = df[df['price_inr'].notna()].reset_index(drop=True)\n",
    "df['price_tier'] = pd.qcut(df['price_inr'], q=3, labels=[0,1,2]).astype(int)\n",
    "\n",
    "# -----------------------\n",
    "# 3. Embeddings (SBERT recommended) with fallback\n",
    "# -----------------------\n",
    "USE_SBERT = True\n",
    "emb = None\n",
    "try:\n",
    "    if USE_SBERT:\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        print(\"Using SBERT embeddings (all-MiniLM-L6-v2).\")\n",
    "        sbert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        emb = sbert.encode(df['text_for_emb'].astype(str).tolist(), batch_size=128, show_progress_bar=True)\n",
    "except Exception:\n",
    "    print(\"SBERT not available or failed — falling back to Keras TextVectorization + BiLSTM encoder.\")\n",
    "    USE_SBERT = False\n",
    "\n",
    "if not USE_SBERT:\n",
    "    MAX_VOCAB = 10000; SEQ_LEN = 32; EMBED_DIM = 64; LSTM_UNITS = 64\n",
    "    texts = df['text_for_emb'].astype(str).values\n",
    "    vectorizer = TextVectorization(max_tokens=MAX_VOCAB, output_sequence_length=SEQ_LEN)\n",
    "    vectorizer.adapt(texts)\n",
    "    # small encoder\n",
    "    inp = layers.Input(shape=(1,), dtype=tf.string)\n",
    "    x = vectorizer(inp)\n",
    "    x = layers.Embedding(input_dim=len(vectorizer.get_vocabulary()), output_dim=EMBED_DIM, mask_zero=True)(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(LSTM_UNITS))(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    enc = models.Model(inp, x)\n",
    "    emb = enc.predict(texts, batch_size=256, verbose=1)\n",
    "\n",
    "df['embedding'] = list(emb)\n",
    "EMB_DIM = emb.shape[1]\n",
    "\n",
    "# -----------------------\n",
    "# 4. Engineer features helpful for tier classification\n",
    "# -----------------------\n",
    "# manufacturer group & stats\n",
    "le_man = LabelEncoder()\n",
    "manu_counts = df['manufacturer'].value_counts()\n",
    "rare_manu = manu_counts[manu_counts <= 10].index\n",
    "df['manu_group'] = df['manufacturer'].apply(lambda x: 'other' if x in rare_manu else x)\n",
    "df['manu_id'] = le_man.fit_transform(df['manu_group'].astype(str))\n",
    "\n",
    "# composition key & competition count\n",
    "df['composition_key'] = df['primary_ing_clean'].astype(str) + '||' + df['strength_mg'].astype(str)\n",
    "df['comp_count'] = df.groupby('composition_key')['product_id'].transform('count')\n",
    "\n",
    "# cluster: PCA on embeddings -> kmeans minibatch to get cheap cluster id\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "pca = PCA(n_components=16, random_state=RND)\n",
    "emb_pca = pca.fit_transform(np.vstack(df['embedding'].values))\n",
    "for i in range(emb_pca.shape[1]):\n",
    "    df[f'emb_pca_{i}'] = emb_pca[:, i]\n",
    "mbk = MiniBatchKMeans(n_clusters=min(150, max(10, df.shape[0]//1000)), batch_size=4096, random_state=RND)\n",
    "df['equivalence_cluster'] = mbk.fit_predict(emb_pca)\n",
    "\n",
    "# cluster-level price medians (weak but useful)\n",
    "df['cluster_price_med'] = df.groupby('equivalence_cluster')['price_inr'].transform('median')\n",
    "df['manu_price_med'] = df.groupby('manu_group')['price_inr'].transform('median')\n",
    "\n",
    "# unit price\n",
    "df['cost_per_unit'] = df['price_inr'] / (df['pack_num'] + 1e-9)\n",
    "\n",
    "# create small categorical features that help classification\n",
    "df['dosage_form_cat'] = df['dosage_form'].astype(str).fillna('unknown')\n",
    "le_dos = LabelEncoder(); df['dosage_id'] = le_dos.fit_transform(df['dosage_form_cat'])\n",
    "\n",
    "# -----------------------\n",
    "# 5. Prepare train/test splits and numeric scaling\n",
    "# -----------------------\n",
    "features_numeric = ['pack_num','strength_mg','comp_count','cluster_price_med','manu_price_med','cost_per_unit'] + [f'emb_pca_{i}' for i in range(emb_pca.shape[1])]\n",
    "num_scaler = StandardScaler()\n",
    "df_scaled = df.copy()\n",
    "df_scaled[features_numeric] = num_scaler.fit_transform(df_scaled[features_numeric].fillna(0))\n",
    "\n",
    "# train/val/test stratified by tier\n",
    "train_df, temp_df = train_test_split(df_scaled, test_size=0.25, random_state=RND, stratify=df_scaled['price_tier'])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=RND, stratify=temp_df['price_tier'])\n",
    "print(\"sizes:\", len(train_df), len(val_df), len(test_df))\n",
    "\n",
    "# -----------------------\n",
    "# 6. Build model inputs (embeddings and categorical embeddings)\n",
    "# -----------------------\n",
    "def make_inputs(d):\n",
    "    return {\n",
    "        'emb_input': np.vstack(d['embedding'].values).astype('float32'),\n",
    "        'manu_input': d['manu_id'].astype('int32').values,\n",
    "        'dosage_input': d['dosage_id'].astype('int32').values,\n",
    "        'num_input': d[features_numeric].astype('float32').values\n",
    "    }\n",
    "\n",
    "X_train = make_inputs(train_df)\n",
    "y_train = train_df['price_tier'].astype('int32').values\n",
    "X_val = make_inputs(val_df)\n",
    "y_val = val_df['price_tier'].astype('int32').values\n",
    "X_test = make_inputs(test_df)\n",
    "y_test = test_df['price_tier'].astype('int32').values\n",
    "\n",
    "# -----------------------\n",
    "# 7. Compute class weights\n",
    "# -----------------------\n",
    "classes = np.unique(y_train)\n",
    "cw = class_weight.compute_class_weight('balanced', classes=classes, y=y_train)\n",
    "class_weight_dict = dict(enumerate(cw))\n",
    "print(\"Class weights:\", class_weight_dict)\n",
    "\n",
    "# -----------------------\n",
    "# 8. Build improved classification NN\n",
    "# -----------------------\n",
    "# Inputs\n",
    "emb_in = layers.Input(shape=(EMB_DIM,), name='emb_input')\n",
    "manu_in = layers.Input(shape=(), dtype='int32', name='manu_input')\n",
    "dosage_in = layers.Input(shape=(), dtype='int32', name='dosage_input')\n",
    "num_in = layers.Input(shape=(len(features_numeric),), dtype='float32', name='num_input')\n",
    "\n",
    "# categorical embeddings\n",
    "MANU_VOCAB = df_scaled['manu_id'].nunique() + 2\n",
    "MANU_EMB_DIM = min(32, max(8, MANU_VOCAB//10))\n",
    "DOSAGE_VOCAB = df_scaled['dosage_id'].nunique() + 2\n",
    "DOSAGE_EMB_DIM = min(8, max(4, DOSAGE_VOCAB//4))\n",
    "\n",
    "manu_emb = layers.Embedding(input_dim=MANU_VOCAB, output_dim=MANU_EMB_DIM, name='manu_emb')(manu_in)\n",
    "manu_emb = layers.Flatten()(manu_emb)\n",
    "dos_emb = layers.Embedding(input_dim=DOSAGE_VOCAB, output_dim=DOSAGE_EMB_DIM, name='dos_emb')(dosage_in)\n",
    "dos_emb = layers.Flatten()(dos_emb)\n",
    "\n",
    "# concat\n",
    "x = layers.Concatenate()([emb_in, manu_emb, dos_emb, num_in])\n",
    "\n",
    "# a slightly deeper block with batchnorm & dropout\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "\n",
    "out = layers.Dense(3, activation='softmax', name='tier')(x)\n",
    "\n",
    "tier_model = models.Model(inputs=[emb_in, manu_in, dosage_in, num_in], outputs=out)\n",
    "# Prioritize classification: optimizer + lr\n",
    "tier_model.compile(optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "                   loss='sparse_categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "tier_model.summary()\n",
    "\n",
    "# -----------------------\n",
    "# 9. Train with callbacks (monitor val accuracy and val macro-f1 via callback)\n",
    "# -----------------------\n",
    "# Macro-F1 is not a built-in Keras metric; we'll compute on val at epoch end using a callback.\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class ValMetricsCallback(callbacks.Callback):\n",
    "    def __init__(self, val_data, batch_size=1024):\n",
    "        super().__init__()\n",
    "        self.x_val, self.y_val = val_data\n",
    "        self.batch_size = batch_size\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        preds = self.model.predict(self.x_val, batch_size=self.batch_size, verbose=0)\n",
    "        preds_cls = np.argmax(preds, axis=1)\n",
    "        mac_f1 = f1_score(self.y_val, preds_cls, average='macro')\n",
    "        logs = logs or {}\n",
    "        logs['val_macro_f1'] = mac_f1\n",
    "        print(f\" — val_macro_f1: {mac_f1:.4f}\")\n",
    "\n",
    "val_cb = ValMetricsCallback(((X_val['emb_input'], X_val['manu_input'], X_val['dosage_input'], X_val['num_input']), y_val), batch_size=1024)\n",
    "es = callbacks.EarlyStopping(monitor='val_macro_f1', mode='max', patience=6, restore_best_weights=True, verbose=1)\n",
    "rlr = callbacks.ReduceLROnPlateau(monitor='val_macro_f1', mode='max', factor=0.5, patience=3, min_lr=1e-7, verbose=1)\n",
    "mc = callbacks.ModelCheckpoint('tier_nn_improved.h5', monitor='val_macro_f1', mode='max', save_best_only=True, verbose=1)\n",
    "\n",
    "# Note Keras doesn't accept class_weight for a single-output sparse_categorical if you pass dict in older TF versions.\n",
    "# We pass class_weight mapping directly to fit\n",
    "history = tier_model.fit(\n",
    "    x = {'emb_input': X_train['emb_input'], 'manu_input': X_train['manu_input'],\n",
    "         'dosage_input': X_train['dosage_input'], 'num_input': X_train['num_input']},\n",
    "    y = y_train,\n",
    "    validation_data = ({'emb_input': X_val['emb_input'], 'manu_input': X_val['manu_input'],\n",
    "                        'dosage_input': X_val['dosage_input'], 'num_input': X_val['num_input']}, y_val),\n",
    "    epochs = 60,\n",
    "    batch_size = 256,\n",
    "    class_weight = class_weight_dict,\n",
    "    callbacks = [val_cb, es, rlr, mc],\n",
    "    verbose = 2\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# 10. Evaluate on test set\n",
    "# -----------------------\n",
    "preds_test = tier_model.predict({'emb_input': X_test['emb_input'], 'manu_input': X_test['manu_input'],\n",
    "                                 'dosage_input': X_test['dosage_input'], 'num_input': X_test['num_input']}, batch_size=1024)\n",
    "preds_cls = np.argmax(preds_test, axis=1)\n",
    "acc = accuracy_score(y_test, preds_cls)\n",
    "mac_f1 = f1_score(y_test, preds_cls, average='macro')\n",
    "print(\"\\nTest accuracy:\", acc)\n",
    "print(\"Test macro F1:\", mac_f1)\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, preds_cls, digits=4))\n",
    "print(\"\\nConfusion matrix:\\n\", confusion_matrix(y_test, preds_cls))\n",
    "\n",
    "# Save final model\n",
    "tier_model.save('tier_nn_improved.h5')\n",
    "print(\"Saved model -> tier_nn_improved.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
